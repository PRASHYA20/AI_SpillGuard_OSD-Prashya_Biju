import streamlit as st
import numpy as np
from PIL import Image
import io
import os
import cv2
import torch
import torchvision.transforms as transforms

# Set page config
st.set_page_config(page_title="Oil Spill Detection", layout="wide")

st.title("üåä Oil Spill Detection")
st.write("Upload satellite imagery for oil spill detection")

# Check for model files
def find_model_files():
    files = os.listdir('.')
    model_files = [f for f in files if f.endswith(('.pth', '.pt', '.pkl'))]
    return model_files

model_files = find_model_files()

# File status
st.sidebar.header("üìÅ File Status")
if model_files:
    st.sidebar.success(f"Found model file: {model_files[0]}")
    file_size = os.path.getsize(model_files[0]) / (1024 * 1024)
    st.sidebar.write(f"Size: {file_size:.1f} MB")
else:
    st.sidebar.error("No model file found!")
    st.sidebar.info("To enable AI detection, ensure 'oil_spill_model_deploy.pth' is in your repository")

# Settings
st.sidebar.header("‚öôÔ∏è Settings")
confidence_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 0.9, 0.5, 0.1)
show_analysis = st.sidebar.checkbox("Show Detailed Analysis", value=True)

def correct_preprocess_image(image, target_size=(256, 256)):
    """
    CORRECTED preprocessing that matches your model training
    """
    # Convert to numpy and keep original for overlay
    if isinstance(image, Image.Image):
        original_image = np.array(image)
    else:
        original_image = image.copy()
    
    # Store original dimensions
    original_h, original_w = original_image.shape[:2]
    
    # Resize for model input
    image_resized = cv2.resize(original_image, target_size)
    
    # Normalize to [0,1] - MATCH YOUR MODEL'S TRAINING
    image_normalized = image_resized.astype(np.float32) / 255.0
    
    # Convert to tensor and normalize properly
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats
    ])
    
    image_tensor = transform(image_resized).unsqueeze(0)  # Add batch dimension
    
    return image_tensor, original_image, (original_h, original_w), image_resized

def correct_postprocess_mask(mask_pred, original_shape, target_size=(256, 256)):
    """
    CORRECTED postprocessing for proper overlay
    """
    # Remove batch dimension and convert to numpy
    if isinstance(mask_pred, torch.Tensor):
        mask_pred = mask_pred.squeeze().detach().cpu().numpy()
    
    # Handle different model output formats
    if len(mask_pred.shape) == 3:  # [C, H, W] or [H, W, C]
        if mask_pred.shape[0] == 1 or mask_pred.shape[0] == 2:  # [C, H, W]
            mask_pred = mask_pred.transpose(1, 2, 0)
        
        # For multi-class, take argmax; for binary, use threshold
        if mask_pred.shape[-1] > 1:
            mask_binary = np.argmax(mask_pred, axis=-1)
        else:
            mask_binary = (mask_pred[..., 0] > 0.5).astype(np.uint8)
    else:  # Already 2D
        mask_binary = (mask_pred > 0.5).astype(np.uint8)
    
    # Resize back to original image size using proper interpolation
    mask_original_size = cv2.resize(
        mask_binary.astype(np.float32), 
        (original_shape[1], original_shape[0]), 
        interpolation=cv2.INTER_NEAREST  # Use nearest to preserve binary values
    )
    
    return mask_original_size

def create_correct_overlay(original_image, mask, alpha=0.6):
    """
    CORRECTED overlay creation that doesn't modify original image
    """
    # Ensure original image is uint8
    if original_image.dtype != np.uint8:
        original_image = (original_image * 255).astype(np.uint8)
    
    # Create a copy for overlay
    overlay = original_image.copy()
    
    # Create colored mask (red for oil spills)
    colored_mask = np.zeros_like(overlay)
    colored_mask[mask > 0] = [255, 0, 0]  # Red color
    
    # Blend overlay
    mask_indices = mask > 0
    overlay[mask_indices] = cv2.addWeighted(
        overlay[mask_indices], 1 - alpha, 
        colored_mask[mask_indices], alpha, 0
    )
    
    return overlay

def load_and_predict(model_path, image_tensor):
    """
    Simulate model prediction - REPLACE WITH YOUR ACTUAL MODEL LOADING
    """
    try:
        # TODO: Replace with your actual model loading
        # model = torch.load(model_path, map_location='cpu')
        # model.eval()
        # with torch.no_grad():
        #     prediction = model(image_tensor)
        
        # For now, return a synthetic prediction that matches your model output
        batch_size, channels, height, width = image_tensor.shape
        synthetic_pred = torch.randn(batch_size, 1, height, width)  # Simulate model output
        
        return synthetic_pred
    except Exception as e:
        st.error(f"Model loading failed: {e}")
        return None

# Main app
uploaded_file = st.file_uploader("üì§ Upload Satellite Image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Load image
    image = Image.open(uploaded_file).convert("RGB")
    
    # Display layout
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("üõ∞Ô∏è Original Image")
        st.image(image, use_container_width=True)
        st.write(f"Size: {image.size}")
    
    # Check if we have a model file
    if model_files:
        st.info("üî∏ AI Model Available - Running in Analysis Mode")
        
        with st.spinner("üîÑ Analyzing image..."):
            # CORRECTED preprocessing
            image_tensor, original_array, original_shape, resized_image = correct_preprocess_image(image)
            
            # Get prediction (replace with your actual model call)
            prediction = load_and_predict(model_files[0], image_tensor)
            
            if prediction is not None:
                # CORRECTED postprocessing
                final_mask = correct_postprocess_mask(prediction, original_shape)
                
                # Apply confidence threshold
                if len(final_mask.shape) == 2:
                    final_mask_binary = (final_mask > confidence_threshold).astype(np.uint8) * 255
                else:
                    final_mask_binary = final_mask
                
                # CORRECTED overlay creation
                overlay_image = create_correct_overlay(original_array, final_mask_binary)
                
                # Convert back to PIL for display
                overlay_pil = Image.fromarray(overlay_image)
                mask_pil = Image.fromarray(final_mask_binary)
                
                # Display results
                with col2:
                    st.subheader("üé≠ Detection Mask")
                    st.image(mask_pil, use_container_width=True, clamp=True)
                    st.write("White = Potential oil spill areas")
                
                with col3:
                    st.subheader("üõ¢Ô∏è Oil Spill Overlay")
                    st.image(overlay_pil, use_container_width=True)
                    st.write("Red = Detected oil spill regions")
                
                # Analysis
                if show_analysis:
                    st.subheader("üìä Analysis Results")
                    
                    # Calculate statistics on the CORRECT mask
                    total_pixels = final_mask_binary.size
                    oil_pixels = np.sum(final_mask_binary > 0)
                    coverage = (oil_pixels / total_pixels) * 100 if total_pixels > 0 else 0
                    
                    col_stats1, col_stats2, col_stats3 = st.columns(3)
                    
                    with col_stats1:
                        st.metric("Spill Coverage", f"{coverage:.2f}%")
                    with col_stats2:
                        st.metric("Affected Pixels", f"{oil_pixels:,}")
                    with col_stats3:
                        st.metric("Confidence Level", f"{confidence_threshold:.1f}")
                    
                    # Interpretation
                    st.subheader("üîç Interpretation")
                    if coverage > 10:
                        st.error("üö® **HIGH RISK** - Significant oil spill detected")
                    elif coverage > 1:
                        st.warning("‚ö†Ô∏è **MEDIUM RISK** - Notable oil contamination")
                    elif coverage > 0.1:
                        st.info("‚ÑπÔ∏è **LOW RISK** - Minor oil detection")
                    else:
                        st.success("‚úÖ **CLEAN** - No significant oil detected")
            
            else:
                st.error("‚ùå Prediction failed - using demo mode")
                # Fallback to demo mode
                with col2:
                    st.subheader("üé≠ Detection Mask")
                    st.info("Model prediction unavailable")
                with col3:
                    st.subheader("üõ¢Ô∏è Oil Spill Overlay")
                    st.info("Model prediction unavailable")
        
        # Download section
        st.subheader("üíæ Download Results")
        
        col_dl1, col_dl2 = st.columns(2)
        
        with col_dl1:
            if 'final_mask_binary' in locals():
                mask_img = Image.fromarray(final_mask_binary)
                buf_mask = io.BytesIO()
                mask_img.save(buf_mask, format="PNG")
                st.download_button(
                    label="üì• Download Detection Mask",
                    data=buf_mask.getvalue(),
                    file_name="oil_spill_mask.png",
                    mime="image/png",
                    use_container_width=True
                )
        
        with col_dl2:
            if 'overlay_pil' in locals():
                buf_overlay = io.BytesIO()
                overlay_pil.save(buf_overlay, format="PNG")
                st.download_button(
                    label="üì• Download Overlay Image",
                    data=buf_overlay.getvalue(),
                    file_name="oil_spill_overlay.png",
                    mime="image/png",
                    use_container_width=True
                )
    
    else:
        # No model file
        st.warning("üî∏ AI Model Not Available")
        
        with col2:
            st.subheader("‚ÑπÔ∏è Information")
            st.write("To enable oil spill detection, add your model file to the repository")
        
        with col3:
            st.subheader("üìã Current Files")
            files = os.listdir('.')
            for file in sorted(files)[:10]:
                st.write(f"- `{file}`")

else:
    st.info("üëÜ **Please upload a satellite image to begin analysis**")

# Instructions
with st.expander("üîß Setup Instructions"):
    st.markdown("""
    **Key fixes in this version:**
    
    1. **Correct preprocessing** with proper normalization
    2. **Proper mask resizing** using INTER_NEAREST to preserve edges
    3. **Non-destructive overlay** that doesn't modify original image
    4. **Tensor-compatible processing** for real model integration
    
    **Replace `load_and_predict` with your actual model loading code:**
    ```python
    def load_and_predict(model_path, image_tensor):
        # Your actual model loading code here
        model = torch.load(model_path, map_location='cpu')
        model.eval()
        with torch.no_grad():
            prediction = model(image_tensor)
        return prediction
    ```
    """)
